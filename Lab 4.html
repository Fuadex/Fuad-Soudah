<!DOCTYPE html>
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    <link href="css/bootstrap.min.css" rel="stylesheet">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<script src="jquery-3.2.1.min.js"></script>
<link rel="stylesheet" href="fuad css.css" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">

<style>

body{
  background-image: linear-gradient(0deg, rgba(0, 0, 0,1), rgba(0,0,0,0.7), rgba(255,255,255,0.7), rgba(255,255,255,0.9), rgba(255, 255, 255,1)), url(DSC_1559-4.jpg);
      background-repeat: no-repeat;
    background-size: cover;
    background-position: center;
    overflow-x: hidden;
}

h2{
  background:none;
  padding-top:8px;
  padding-bottom:0px;
}

.panel{
  background-color:rgba(255,255,255,0.65);
  color: black; text-shadow: white 0em 0em 0.5em;
  font-family:'Roboto', sans-serif;
border:1px solid black;
}

h4{
  padding-top:13.5px;
  padding-bottom:15px;
}

.parallax { 
    /* The image used */
    background-image: url("DSC_3698b.jpg");

    /* Full height */
    min-height: 100%; 

    /* Create the parallax scrolling effect */
    position: relative;
    opacity: 0.65;
    background-attachment: fixed;
    background-position: center;
    background-repeat: no-repeat;
    background-size: cover;
}

.text{
    opacity:0;
      font-weight: bold;
    z-index: 1;
    position: absolute;
    font-size:2vw;
    left: 50%;
    top: 50%;
    transform: translate(-50%, -50%);
background-color:rgba(255,255,255,0.65);
    color: white; text-shadow: white 0em 0em 0.5em;
  font-family:'Roboto', sans-serif;
  padding-top:0.25em;
  padding-bottom:0.25em;
  padding-left:0.5em;
  padding-right:0.5em;
  border-radius: 10px;
  border-style:solid;
  border-width:1px;
  border-color:black;
      -webkit-transition: all 0.2s linear;
       -moz-transition: all 0.2s linear;
        -ms-transition: all 0.2s linear;
         -o-transition: all 0.2s linear;
            transition: all 0.2s linear;
}

a.darken img {
    display: block;
    
    -webkit-transition: all 0.5s linear;
       -moz-transition: all 0.5s linear;
        -ms-transition: all 0.5s linear;
         -o-transition: all 0.5s linear;
            transition: all 0.5s linear;
}

a.darken:hover img {
    opacity: 0.7;           
}

a.darken:hover .text{color:black;
   opacity:1;
    -webkit-transition: all 0.3s linear;
       -moz-transition: all 0.3s linear;
        -ms-transition: all 0.3s linear;
         -o-transition: all 0.3s linear;
            transition: all 0.3s linear;
}

video{
	width:50%;
}

center img{
  border-width:0.1vw;
  background:white;
  padding:2vw;
  margin-top:1vw;
  margin-bottom:1vw;
}

center:hover img{
  border-width:0.2vw;
  border-color:#222;
  padding-left:3vw;
  padding-right:3vw;
}

.noborder{
  border-width:0px !important;
  box-shadow:none !important;
}

pre{
  border-width:1px;
  border-color:black;
  margin-top:1vw;
  padding:1vw;
      -webkit-transition: all 0.5s ease !important;
       -moz-transition: all 0.5s ease !important;
        -ms-transition: all 0.5s ease !important;
         -o-transition: all 0.5s ease !important;
            transition: all 0.5s ease !important;
}

pre:hover{
  border-width:2px;
  border-radius:2vw;
  padding:5vw;
  background:white;
    -webkit-transition: all 0.5s ease !important;
       -moz-transition: all 0.5s ease !important;
        -ms-transition: all 0.5s ease !important;
         -o-transition: all 0.5s ease !important;
            transition: all 0.5s ease !important;
}

.nopadding{
  padding:0px !important;
}
.nopadding:hover{
transform: scale(1.5);
border-radius: 3vw;
}

</style>


  <script type="text/javascript">
    ImageArray = new Array();
    ImageArray[0] = 'DSC_3698bb.jpg';
    ImageArray[1] = 'DSC_3698cc.jpg';
  

function getRandomImage() {
    var num = Math.floor( Math.random() * 2);
    var img = ImageArray[num];
    document.getElementById("randImage").innerHTML = ('<img src="' + img + '" width="100%">')

}

</script>

</head>
<body onload="getRandomImage()">
<script src="navigation.js"></script>

<!-- BODY BODY BODY-->



<div class="container-fluid">

<div class="row">
<center><img class="noborder" src="https://i.imgur.com/0Bvb2gq.png" width="100%"></center>
</div><br>

<center><img src="https://i.imgur.com/1DnH45U.png" width="70%"></center>

<div class="row">
  <div class="col-md-4 col-md-offset-2">
    <a href="Blog v2.html" class="darken"><div class="text">Light!</div><img src="https://5xebgq.db.files.1drv.com/y4m8uoT9__xJqVk_mzjNq92uc86jH1WsHNLkhP01J9oblB3PL9oCIR9I1ISMTXsGgA2DL8yFB0Mru9QPqZ8ESop1r3X--sGhhOcqykR4dJLl4IfGnnXFuZHIM6nwjNjknovtMd_LGigimYmC5lYvVKZudxJO-S_x1PKRwqioqOGCZ9xmsA8NJ6k__prKrJXZm1tTC1Xzd6gLhF4jD5NViLgLQ?width=660&height=440&cropmode=none" width="100%"></a><br>
  </div>
  <div class="col-md-4 col-md-offset-0 panel">
    <br>
We were tasked with running a Processing sketch that would utilise the OpenCV library.<br><br>

  </div><br>
</div>

<center><img src="https://i.imgur.com/QdISIgP.png" width="70%"></center>

<div class="row">
</div><br>

<div class="row">
  <div class="col-md-4 col-md-offset-2">
    <a href="Blog v2.html" class="darken"><div class="text">Tut Exercise</div><img src="https://5xedgq.db.files.1drv.com/y4m08i2RVsO3iIG0KW5BA_HXhf1sz1Ie1behzu0BjctGU3gLGVoYZ6djIWEwnjSo1aIbwY88MZIW9t4aDQL-xWdEJ4XfuTL4WgBBJ4WTLHf10JauyHSOjrX8UVkf-ZTGuVliqKe-JcKr-5KXntcm8mueRgfVz-lI5tpkZH5uZgPXxsEJusMQihUf1KA0LQakYIX6wCQw1jDpOfitau6fSBXuQ?width=660&height=440&cropmode=none" width="100%"></a><br>
  </div>
  <div class="col-md-4 col-md-offset-0 panel">
<br>

My Surface Book’s camera does not work well with the processing.video library, as the video only works in predefined resolutions, crops off the video in many cases, the colours are skewed and tinted green, and the framerate is substantially bad.<br><br>

Getting a workaround implemented was the main challenge, that I was still not able to technically overcome as of yet.<br><br>

  </div><br>
</div>

<center><img src="https://i.imgur.com/kapsHFL.png" width="70%"></center>

<div class="row">
  <div class="col-md-4 col-md-offset-2">
    <a href="Blog v2.html" class="darken"><div class="text">Collaboration</div><img src="https://illx3q.by.files.1drv.com/y4mN2qCAUiEpAP3gKpq4Erm_8r8yzR5U5ov9ZWZvPCQdhfWjn96wn9fC-CAAHeZHiTX0asOqrd7osnr5z-D_Z8yz1evfPlRmJbzR7ryC2HAgEvSp4xsq1Xa1eE0ra-DaMqGo61PKNpw2LCFOuRkdOeFzkb75YfJTdG-e8aevoh0Lcup-lQVO94DsXRWNyaifjwavYvoY4OqS9I3GpjvsOyysw?width=3240&height=2160&cropmode=none" width="100%"></a><br>
  </div>
  <div class="col-md-4 col-md-offset-0 panel">
<br>

I was successfully able to run the OpenCV code and get some basic functionality working. I also managed to find a workaround to get a proper video feature implemented.<br><br>

  </div><br>
</div>

<center><img src="https://i.imgur.com/vok7uVX.png" width="70%"></center>

<div class="row">
  <div class="col-md-4 col-md-offset-2">
    <a href="Blog v2.html" class="darken"><div class="text">Collaboration</div><img src="https://iflx3q.by.files.1drv.com/y4mT61Wk3adI07or6STjaIxqPzv99pmKbRCpsMwUhWXf26N12Oa7PZNH-2oxXeYh4A9MfhqSr5d8pF5qmwyczGgx2jGTRuFX5JVP7yS0YFdIpZaLVh_X0DrOOMVMBboJ4n8kqrC_u_bPMlEPxhtKBWF4zra2n5AEMTgL-Iu4sIHVVtE3e8O4oUFNCXeRS7SAlsJnFKRabai7mVbVkZEYqREbQ?width=3240&height=2160&cropmode=none" width="100%"></a><br>
  </div>
  <div class="col-md-4 col-md-offset-0 panel">
<br>
I wasn't able to get OpenCV to work entirely in proper fashion, as it glitches substantially. I will make a few more attempts merging the codes or perhaps messing with the codecs in relation to processing.video.<br><br>

  </div><br>
</div>

<center><img src="https://i.imgur.com/xa6xhMw.png" width="70%"></center>

<div class="row">
  <div class="col-md-8 col-md-offset-2 noborder">
    <pre>
//Processing Code
// - Super Fast Blur v1.1 by Mario Klingemann 
// - BlobDetection library

import processing.video.*;
import blobDetection.*;
import de.humatic.dsj.*;
import java.awt.image.BufferedImage;

DCapture cap;
Capture cam;
BlobDetection theBlobDetection;
PImage img;
boolean newFrame=false;

// ==================================================
// setup()
// ==================================================
void setup()
{
  // Size of applet
  size(1920, 1080);
  background(0);
  cap = new DCapture();
  // Capture
  //cam = new Capture(this, 1920, 1080, 30);
        // Comment the following line if you use Processing 1.5
        //cam.start();
        
  // BlobDetection
  // img which will be sent to detection (a smaller copy of the cam frame);
  img = new PImage(80,60); 
  theBlobDetection = new BlobDetection(img.width, img.height);
  theBlobDetection.setPosDiscrimination(true);
  theBlobDetection.setThreshold(0.2f); // will detect bright areas whose luminosity > 0.2f;
}

// ==================================================
// captureEvent()
// ==================================================
void captureEvent(Capture cam)
{
  cam.read();
  newFrame = true;
}

// ==================================================
// draw()
// ==================================================
void draw()
{
  image(cap.updateImage(), 0, 0, cap.width, cap.height);
  if (newFrame)
  {
    newFrame=false;
    image(cam,0,0,width,height);
    img.copy(cam, 0, 0, cam.width, cam.height, 
        0, 0, img.width, img.height);
    fastblur(img, 2);
    theBlobDetection.computeBlobs(img.pixels);
    drawBlobsAndEdges(true,true);
  }
}

// ==================================================
// drawBlobsAndEdges()
// ==================================================
void drawBlobsAndEdges(boolean drawBlobs, boolean drawEdges)
{
  noFill();
  Blob b;
  EdgeVertex eA,eB;
  for (int n=0 ; n
// ==================================================
void fastblur(PImage img,int radius)
{
 if (radius<1){
    return;
  }
  int w=img.width;
  int h=img.height;
  int wm=w-1;
  int hm=h-1;
  int wh=w*h;
  int div=radius+radius+1;
  int r[]=new int[wh];
  int g[]=new int[wh];
  int b[]=new int[wh];
  int rsum,gsum,bsum,x,y,i,p,p1,p2,yp,yi,yw;
  int vmin[] = new int[max(w,h)];
  int vmax[] = new int[max(w,h)];
  int[] pix=img.pixels;
  int dv[]=new int[256*div];
  for (i=0;i<256*div;i++){
    dv[i]=(i/div);
  }

  yw=yi=0;

  for (y=0;y>16;
      gsum+=(p & 0x00ff00)>>8;
      bsum+= p & 0x0000ff;
    }
    for (x=0;x>16;
      gsum+=((p1 & 0x00ff00)-(p2 & 0x00ff00))>>8;
      bsum+= (p1 & 0x0000ff)-(p2 & 0x0000ff);
      yi++;
    }
    yw+=w;
  }

  for (x=0;x


</pre>

<pre>
  //Processing
import de.humatic.dsj.*;
import java.awt.image.BufferedImage;
 
class DCapture implements java.beans.PropertyChangeListener {
 
  private DSCapture capture;
  public int width, height;
 
  DCapture() {
    DSFilterInfo[][] dsi = DSCapture.queryDevices();
    capture = new DSCapture(DSFiltergraph.DD7, dsi[0][0], false, 
    DSFilterInfo.doNotRender(), this);
    width = capture.getDisplaySize().width;
    height = capture.getDisplaySize().height;
  }
 
  public PImage updateImage() {
    PImage img = createImage(width, height, RGB);
    BufferedImage bimg = capture.getImage();
    bimg.getRGB(0, 0, img.width, img.height, img.pixels, 0, img.width);
    img.updatePixels();
    return img;
  }
 
  public void propertyChange(java.beans.PropertyChangeEvent e) {
    switch (DSJUtils.getEventType(e)) {
    }
  }
}

</pre>

</div>
</div>

<center><img src="https://i.imgur.com/UI0PAbb.png" width="70%"></center>


<center><img class="nopadding" src="https://kvnwaa.by.files.1drv.com/y4mBjwKGie5cp_xg6q1vlHar0GwaD8COh39Di6v6Gn_nwIx2XTceogTNinvhwuFP0r2viOHvAYconV-osNH-A8kSnNMUhdld9-4WgHfk0W19MdvzmidMNIgJWqYHTcLRxKE2_fjspJKrZnc0U4mnVG-InofVR69DCSDGztylgWQhEu1edYfTzFIUZwn7A19KvHGw93Ty_PH7GfoWJcMnT0H-Q?width=3240&height=2160&cropmode=none" width="50%"></center>

<center><img class="nopadding" src="https://ivlx3q.by.files.1drv.com/y4mW9tyR_B65YcplMt4lINAkzQNcPbDUkW1t-hSJ8VIPYvPw73PLsh6s_TNEIcJjiu8KwCo6NmwtPHxsg8oEHek8UnWMDbbCEEq9VAx3AUbEyqn6eVqvJ9Jj3dGj_Crc_TQ33Fkw4YnaIyT2tg261qRncTHFeMN9IjH4pojMafPyuupVFU4F2BkJWHRqE-OpQtzEEECKztWwBSmcK25It6bvg?width=3240&height=2160&cropmode=none" width="50%"></center>


<center><img src="https://i.imgur.com/JgVEAWA.png" width="80%"></center>

<div class="row">
<div class="col-md-6 col-md-offset-3 panel">
  <br>
So, to start off I started looking into OpenCV. However, it seemed as if it was malfunctioning, unfortunately.

After the consultation I have done with my tutors, we came to a conclusion that Surface cams do not work properly with OpenCV and that the issue may be unresolvable. But I reckon anything can be resolved, so I looked for a solution and found one potential, that utilised a different technique of processing a video.<br><br>

The solution was found here: <a href="https://forum.processing.org/two/discussion/14403/camera-video-image-slow">Links to an external site.</a><br><br>

And according to the last post, there may be a solution here: <a href="http://www.magicandlove.com/blog/2012/04/10/directshow-for-processing/">Links to an external site.</a><br><br>

The first code didn’t work as I receive an error with a -9 being displayed. But it didn’t matter as I was more interested in the second code, which actually utilised my cam. The showcased solution was a bit counterintuitive, so I messed up my classes. Also, I accidently introduced a 32-bit version of the library which does not work with 64 bit version of my windows. Once I resolved that I looked on whether the video works.<br><br>

It does! But it was cropped out due to resolution. But the colours were now natural and so was the framerate. Improvement!<br><br>

I shifted the resolution from 640.480 to 1920.1080 the maximum offered by my cam. And bingo! Hello world!<br><br>

Although my camera froze up eventually.<br><br>

</div></div>

<center><img src="https://i.imgur.com/Imzj14y.png" width="70%"></center>

<div class="row">
<div class="col-md-6 col-md-offset-3 panel">
	<br>
 Not much, but I'll elaborate soon.
<br><br>

</div></div>

<center><img src="https://i.imgur.com/04zv3Th.png" width="70%"></center>


      <div class="row">
        <div class="col-md-6 col-md-offset-3 panel">
<br>

Interaction based on user's movement. But it would have to rather analyze the behavior of the user rather than entice them to do anything (due to Kinect's being rolledback from the Market).<br><br>

Questions!<br>
Is there a debounce function in Processing?<br>
How does printing PCBs work?<br>
Better sensors instead of Sonic sensors?<br>
Best way to filter signals? I used oversampling.<br><br>

</div></div>

<center><img src="https://i.imgur.com/x3x3smB.png" width="70%"></center>

      <div class="row">
        <div class="col-md-6 col-md-offset-3 panel">
<br>

Techniques!<br>
Science man!<br>
Undersampling?<br>
Aggressive Low Pass Filters (Filtering?)<br>
Sampling Rate?<br>
Filtering<br>
Averaging!<br>
Smoothing<br>
Error Correction<br><br>

</div></div>

      
<div class="row">
	<center><video width="100%" controls>
      <source src="https://onedrive.live.com/download?cid=FCD0FC5C0BEE35A2&resid=FCD0FC5C0BEE35A2%2177072&authkey=AAxjKLyCPSVrgGs" type="video/mp4">
      </video></center>
      </div>

      <div class="row">
  <center><video width="100%" controls>
      <source src="https://onedrive.live.com/download?cid=FCD0FC5C0BEE35A2&resid=FCD0FC5C0BEE35A2%2177074&authkey=AERVal5BJgzBtKI" type="video/mp4">
      </video></center>
      </div>

      <div class="row">
    <center><video width="100%" controls>
      <source src="https://onedrive.live.com/download?cid=FCD0FC5C0BEE35A2&resid=FCD0FC5C0BEE35A2%2177101&authkey=ALxFV3gII-bL2rc" type="video/mp4">
      </video></center>
      </div>

<!--

<div class="row">
<center><h1>Follow-up</h1></center>
</div><br>

<div class="row">
  <div class="col-md-4 col-md-offset-2">
    <a href="Blog v2.html" class="darken"><div class="text">Placemaking</div><img src="https://farm5.staticflickr.com/4694/27993583069_97c07b276a.jpg" width="100%"></a><br>
  </div>
  <div class="col-md-4 col-md-offset-0 panel">
    <center><h4>Intro</h4></center>
    So, here I am, back with Arduino. After a few attempts, one minor, one prompt, one challenging and now the one, in a way ubiquitous, theoretically more constrained, yet potentially more potent to bring technology out to the open and make sure people actually interact and become healthier. In a way I was not entirely into 'designing for wellbeing' concept, while I agree with it and believe there is a strong need for it, I feel that it might not be my thing, ya know? However, one thing I did however manage to connect with and to and it all started back in around 2013, when I felt a strong drive for the redevelopment of my hometown, to which I had to commute for pretty much everyday. Whether to attend my high school classes, or to meet with friends - but the infrastruture did not really support either. So that's probably when my UX story really started, despite me not knowing the techniques, I already have utilized quite a few: Background research, target user interviews, low-fidelity sketches, later on mockups. The number one issue that I have commited to, intended no-misuse on my side, was that I went streight into developing ideas, instead of consulting it with others. At that time I was like, 'whom am I going to consult it with? Barely anybody knew what I was doing as a hobby. And nobody really would in fact approve it unless it was potentially good.' And so it remained a secret and never went beyond the defining stage. Since then, I believe it was only Vivid, which surprisingly became something that I started believing in the work that one may be conducting in terms of enriching the surrounding environment. And now, a factual 18 credit point subject, utilizing a number of areas that I have been dedicated to: Product Design, Sound Design, UX, Interface Design... what does it not utilize really? Arduino, Processing, Product making comes into play and the project will likely evolve way beyond that. Now that I consider as quite beautiful.<br><br>

  </div><br>
</div>

<div class="row">
	<div class="col-md-8 col-md-offset-2">
Nevertheless, what I was told to do here, was really showcase and reflect on how I did and would likely prefer to perform futurewise. So first of all, I am in possession of a new computer system, therefore all of my software was not installed to begin with. I had to download Arduino and Processing softwares. Then my arduino kit was still stranded on the semi-failed weightscale project, very likely due to the dodgy arduino kit that I have (Sparkfun unit). After all, I constructed my device in a way, that it was relatively easy to disassemble. However, it turned out that my cable was stuck inside, therefore I had to fiddle with breaking it out. I had to apply some pressure and I didn't manage to free it out without breaking the structure a bit. But that's okay, I may recycle it someday, I guess. Then another issue came to my mind: what do I do now? Well, I went straight into trying to get something working. So I followed the sparkfun tutorial for launching my RGB LED and, it worked. So I figured: hey! Maybe I'll bind a processing code to the arduino kit? And there I made an attempt. A quite successful one. Nevertheless, I crashed on the Serial.write() bit, as unfortunately serialized code does not quite work well when you wish to send a few separate info. Too bad, so I figured, well, maybe I could do something more physical, then?<br><br>
</div>
</div>

<div class="row">
	<div class="col-md-8 col-md-offset-2">
And so I did! Four buttons, according to my concept, the yellow would unlock the ground pin. And the other: red, green, blue; would just activate each. It didn't take much fidling, as it was just the buttons, that work as a connector itself. This is some cool stuff, easy peasy, but still cool. Along the way I found out that it's absolutely okay to use the RGB LED without any resistors, the same goes for the buttons. Cause what would they be needed for? They just carry on the electricity further, when pressed that is. The very next thing was to see whether both of the methods for launching the RGB LED work. Buttons worked. The processing code, after a few fixes: started to work as well. So there it is. Now I have an interesting foundation, although still am in need of some ways of sending data two-way. Hey, perhaps via bluetooth finally? So next step: Firmata.<br><br>
</div>
</div>

-->

<br>
</div>

<script src="footer.js"></script>

<script>
document.getElementById('button').onclick = function() {
    this.__toggle = !this.__toggle;
    var target = document.getElementById('hidden_content');
    if( this.__toggle) {
        target.style.height = target.scrollHeight+"px";
        this.firstChild.nodeValue = "Games and Play";
    }
    else {
        target.style.height = 0;
        this.firstChild.nodeValue = "Games and Play";
        setTimeout(function() {
       window.scrollTo(0,window.scrollY-300);
        TopscrollTo();
    }, 0);
    }
}
</script>

<script>
document.getElementById('button2').onclick = function() {
    this.__toggle = !this.__toggle;
    var target = document.getElementById('hidden_content2');
    if( this.__toggle) {
        target.style.height = target.scrollHeight+"px";
        this.firstChild.nodeValue = "Human-Computer Interaction 2";
    }
    else {
        target.style.height = 0;
        this.firstChild.nodeValue = "Human-Computer Interaction 2";
    }
}
</script>

    <script src="js/bootstrap.min.js"></script>
</body>
</html>