<!DOCTYPE html>
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    <link href="../../css/bootstrap.min.css" rel="stylesheet">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<script src="../../jquery-3.2.1.min.js"></script>
<link rel="stylesheet" href="../../fuad css.css" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">

<style>

body{
/*  background:url(https://farm1.staticflickr.com/855/28925466837_276c72fe36_o.jpg);*/
background:url();
      background-repeat: no-repeat;
    background-size: cover;
    background-position: center;
    overflow-x: hidden;
}

.con1{
  background-image:linear-gradient(0deg, rgba(0,0,0,1), rgba(255, 255, 255,0), rgba(255, 255, 255,1)), url(https://jkbi2g.by.files.1drv.com/y4maU55LeuqkSP2d0L6OpeeEj1vDeN1ecFoEB8Od7m855Bz-Nh22LzotN518upZ3bIJGixW-B_Ns2AoBzZ8BgxMMdHcLyuuz77oRpe76zMX_UCHap3X-MdhhpzHrGQLD_SoCiPym08TiXAeqRiRMB0cYAhF0RTyyuLgryf_M-DTFWwUjFJPBAcWhghRZQmYcDWVHWk4vJYMlB98aCqGrkE3kw?width=2124&height=1255&cropmode=none);
        background-repeat: no-repeat;
    background-size: cover;
    background-position: center;
    overflow-x: hidden;
}

.con2{
  background-image:linear-gradient(0deg, rgba(0,0,0,1), rgba(255, 255, 255,0), rgba(0, 0, 0,1)), url(https://jkbh2g.by.files.1drv.com/y4mWahWDaTaTo42cX8Jt6U3dlGpT4OBP9WkTy63e7W3vjlCobtB6aeEbEV-kBjnGh_8StTeO87wuwt-EY8ZhwBJ4_lj25USg3Dqdo2x9n0eARcH1cgHFrWoq7fC1yd451MgWWiEtRNM1vsYgEE4gfL3U478WxnfjsfUywYWaaGDYbP6u05JOJVTq1WTrRPwjGpepAsRkcfUeesquTzlit0yNA?width=2127&height=1256&cropmode=none);
        background-repeat: no-repeat;
    background-size: cover;
    background-position: center;
    overflow-x: hidden;
}

.con3{
  background-image:linear-gradient(0deg, rgba(0,0,0,1), rgba(255, 255, 255,0), rgba(0, 0, 0,1)), url(https://jkbg2g.by.files.1drv.com/y4mK-6EVngFwvsMltN966FNt_Nh7uRmdE3LE6q7wRJChS-N05IS9RttLW61E1IaUqUiNYkOzYA26KwsBkOZpePvNhhn45_9YhOolhkP97m5xA0jOM-Oq8uh8SuejRKXUl_NcQ9RfQFKAdwNIm1MzKNq5rOlc0YTPRjA1DRyIFnPQ8xgTg-Gq-eLW0gx7g_5MIp29DX0ebD1e4nDFW9M3Pi_Ww?width=2124&height=1257&cropmode=none);
        background-repeat: no-repeat;
    background-size: cover;
    background-position: center;
    overflow-x: hidden;
}

.con4{
  background-image:linear-gradient(0deg, rgba(0,0,0,1), rgba(255, 255, 255,0), rgba(0, 0, 0,1)), url(https://jkbi2g.by.files.1drv.com/y4maU55LeuqkSP2d0L6OpeeEj1vDeN1ecFoEB8Od7m855Bz-Nh22LzotN518upZ3bIJGixW-B_Ns2AoBzZ8BgxMMdHcLyuuz77oRpe76zMX_UCHap3X-MdhhpzHrGQLD_SoCiPym08TiXAeqRiRMB0cYAhF0RTyyuLgryf_M-DTFWwUjFJPBAcWhghRZQmYcDWVHWk4vJYMlB98aCqGrkE3kw?width=2124&height=1255&cropmode=none);
        background-repeat: no-repeat;
    background-size: cover;
    background-position: center;
    overflow-x: hidden;
}



h2{
  background:none;
  padding-top:8px;
  padding-bottom:0px;
}

.panel{
  background-color:rgba(255,255,255,0.65);
  color: black; text-shadow: white 0em 0em 0.5em;
  font-family:'Roboto', sans-serif;
border:1px solid black;
}

h4{
  padding-top:13.5px;
  padding-bottom:15px;
}

.parallax { 
    /* The image used */
    background-image: url("DSC_3698b.jpg");

    /* Full height */
    min-height: 100%; 

    /* Create the parallax scrolling effect */
    position: relative;
    opacity: 0.65;
    background-attachment: fixed;
    background-position: center;
    background-repeat: no-repeat;
    background-size: cover;
}

.text{
    opacity:0;
      font-weight: bold;
    z-index: 1;
    position: absolute;
    font-size:1.5em;
    left: 50%;
    top: 50%;
    transform: translate(-50%, -50%);
background-color:rgba(255,255,255,0.65);
    color: white; text-shadow: white 0em 0em 0.5em;
  font-family:'Roboto', sans-serif;
  padding-top:0.25em;
  padding-bottom:0.25em;
  padding-left:0.5em;
  padding-right:0.5em;
  border-radius: 10px;
  border-style:solid;
  border-width:1px;
  border-color:black;
      -webkit-transition: all 0.2s linear;
       -moz-transition: all 0.2s linear;
        -ms-transition: all 0.2s linear;
         -o-transition: all 0.2s linear;
            transition: all 0.2s linear;
}

a.darken img {
    display: block;
    -webkit-transition: all 0.5s linear;
       -moz-transition: all 0.5s linear;
        -ms-transition: all 0.5s linear;
         -o-transition: all 0.5s linear;
            transition: all 0.5s linear;
}

a.darken:hover img {
    opacity: 1 !important;           
}

a.darken:hover .text{color:black;
   opacity:1;
    -webkit-transition: all 0.3s linear;
       -moz-transition: all 0.3s linear;
        -ms-transition: all 0.3s linear;
         -o-transition: all 0.3s linear;
            transition: all 0.3s linear;
}

p{
  margin:15px 5px 15px;
}

iframe {
    height: 26.5vw; /* 100/56.25 = 560/315 = 1.778 */
}

</style>


  <script type="text/javascript">
    ImageArray = new Array();
    ImageArray[0] = 'DSC_3698bb.jpg';
    ImageArray[1] = 'DSC_3698cc.jpg';
  

function getRandomImage() {
    var num = Math.floor( Math.random() * 2);
    var img = ImageArray[num];
    document.getElementById("randImage").innerHTML = ('<img src="' + img + '" width="100%">')

}

</script>

    <link rel="shortcut icon" href="SafariUnity/TemplateData/favicon.ico">
    <link rel="stylesheet" href="SafariUnity/TemplateData/style.css">
    <script src="SafariUnity/TemplateData/UnityProgress.js"></script>
    <script src="SafariUnity/Build/UnityLoader.js"></script>
    <script>
      var gameInstance = UnityLoader.instantiate("gameContainer", "SafariUnity/Build/Safari Unity.json", {onProgress: UnityProgress});
    </script>

</head>
<body onload="getRandomImage()">
<script src="navigation.js"></script>

<!-- BODY BODY BODY-->


<div class="con1">
<div class="container-fluid">
<div class="row">
<center><h1>Week 5 - Enrichment II</h1></center>
</div><br>

<div class="row">
  <div class="col-md-8 col-md-offset-2 panel">
    
  <center><h4><p style="margin-top:15px">Reflections</p></h4></center>
    
    <p>
As for the the Enrichment II assignment I decided to go ahead with the idea of enriching part of a space of where wallabies roam freely about. First of all, I should mention that the idea could potentially be extended to any species that sees the environment in colour. Despite that some animals have slightly and/or radically different way of perceiving the world to make their lives easier, to make it more convenient for them to have access to particular types of food, escape any potential predators nearby and areas that could potentially do harm. Building upon that, I am curious to see whether projected environments, as I would call augmented or even as far as I would go and just call them virtual, although without placing any form of species into any widely known as virtual reality environments but, in order to further elaborate, project those spaces into empty, enclosed spaces by the use of a projection mapping device and a set of prisms and mirrors, refracting and bouncing light of each to throw and disperse the mapping all around the environment.
</p>

<p>
  Effects that I could call as relatively similar to what I'm trying to achieve are attached underneath:
</p>

<!-- Empathy Machine

Face detection as a cue: predator

Wallaby: Doesn't care
Kangaroo: Ready to rumble
Quokka: love you human
Emu: RUN RUN RUN

Response: appropriate sounds

Aim: educating on how different species are likely to respond to
Nocturnal Species

...
Based on the readings, frameworks seem to need to be developed for the assessment of what exactly is the enrichment itself -->
    </p>

      </div><br>
</div>

<center>
    <iframe width="50%" src="https://www.youtube.com/embed/PoJI59K5eAc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center><br>

<center>
  <a href="https://www.google.com/url?sa=i&source=images&cd=&cad=rja&uact=8&ved=0ahUKEwiJxeWo8M3gAhUMVd8KHVTwAmQQMwhtKCEwIQ&url=https%3A%2F%2Fwww.emergingedtech.com%2F2015%2F10%2Fmake-3d-hologram-with-smartphone-tablet-class-project%2F&psig=AOvVaw0hSF942hhS5krkeRi6YMaH&ust=1550874622498837&ictx=3&uact=3"><img style="width:50%;" src="https://www.emergingedtech.com/wp/wp-content/uploads/2015/10/3d-holographic.png"></a>
</center>
</div>

<!-- <div class="row">
  <div class="col-md-2 col-md-offset-2">
    <a href="https://kkbq2g.by.files.1drv.com/y4mLC-4HNHzEfH9EMF1-eair71wYTNBDHKzubgoEpHHioQYqNJhdpY79MCCnx0ZzGYhiTVctbge8_TUgQfgJ18ny-GzQAvK34G1An1AEooNtKDPWWOg8LepGo3EmqAg0rONxwtY9F1jrTTSmdewnQt6NbavAgFbY37rSTgGDiUuwP0Ml-LwtZqES2KosXrUzPH6UwITiklWRqi7-WU9qRUvkQ?width=1024&height=683&cropmode=none" class="darken"><div class="text"><center>Panda vol. 1<br></center></div><img src="https://kkbq2g.by.files.1drv.com/y4mLC-4HNHzEfH9EMF1-eair71wYTNBDHKzubgoEpHHioQYqNJhdpY79MCCnx0ZzGYhiTVctbge8_TUgQfgJ18ny-GzQAvK34G1An1AEooNtKDPWWOg8LepGo3EmqAg0rONxwtY9F1jrTTSmdewnQt6NbavAgFbY37rSTgGDiUuwP0Ml-LwtZqES2KosXrUzPH6UwITiklWRqi7-WU9qRUvkQ?width=1024&height=683&cropmode=none" style="margin-top:20px"width="100%"></a><br>
  </div>
    <div class="col-md-2">
    <a href="https://kkbb2g.by.files.1drv.com/y4mpOW0bphMrcW5p7-a4IIVG6tvqlDIcWX2QACfLfCYhIbmsWvbADVI_LP05Jk6hKYQH-7Xw8S7sHp42MILPYypA7eJo8FkslISMrj1PcpLjHe8zZX3lRQUboo6rhc-1F2pYFH8b7yv7IEkQ9tMurGkz0bGffInAzNntQC-gqSCzXL7z4K_Zv_B4-lBs_Ab3PXBGxMaYHeBqEB2C3ddrm1FwQ?width=1024&height=683&cropmode=none" class="darken"><div class="text"><center>Panda vol. 2<br></center></div><img src="https://kkbb2g.by.files.1drv.com/y4mpOW0bphMrcW5p7-a4IIVG6tvqlDIcWX2QACfLfCYhIbmsWvbADVI_LP05Jk6hKYQH-7Xw8S7sHp42MILPYypA7eJo8FkslISMrj1PcpLjHe8zZX3lRQUboo6rhc-1F2pYFH8b7yv7IEkQ9tMurGkz0bGffInAzNntQC-gqSCzXL7z4K_Zv_B4-lBs_Ab3PXBGxMaYHeBqEB2C3ddrm1FwQ?width=1024&height=683&cropmode=none" style="margin-top:20px"width="100%"></a><br>
  </div>
      <div class="col-md-2">
    <a href="https://kkbp2g.by.files.1drv.com/y4mOd80Qe0pokvXq1IgLt3VobyVbo_8Qe0xfXfj19Cm72QgVLEN7mU80FSugc3RoD6NO8q2ize3zdJJpgx-nXi4aL_JKcDNHmVQVOvpAEfb-tWP5RWKJIfXlbVvO6L05Hh8kXlTvRzciwhigi9eKITLzpFucLS5VXyvP0eIr2vxUbGtUJVzwJweqCQmEe7JYybi9mAECIjxA-80CKLjsIMjjA?width=1024&height=576&cropmode=none" class="darken"><div class="text"><center>Humans vol. 1<br></center></div><img src="https://kkbp2g.by.files.1drv.com/y4mOd80Qe0pokvXq1IgLt3VobyVbo_8Qe0xfXfj19Cm72QgVLEN7mU80FSugc3RoD6NO8q2ize3zdJJpgx-nXi4aL_JKcDNHmVQVOvpAEfb-tWP5RWKJIfXlbVvO6L05Hh8kXlTvRzciwhigi9eKITLzpFucLS5VXyvP0eIr2vxUbGtUJVzwJweqCQmEe7JYybi9mAECIjxA-80CKLjsIMjjA?width=1024&height=576&cropmode=none" style="margin-top:20px"width="100%"></a><br>
  </div>
      <div class="col-md-2">
    <a href="https://hahw3q.db.files.1drv.com/y4mWZUDlsItWK6b8qjiI62D_mW2BeykwiWhZDGN4R5S922uIMyvXksp7A60K-ktAgYxk9fKjVKnvzv-8Gh8Z9GaetVOZuUrYuE4_NUe66M2xMVvaNoV8A27aI-bbQMxZj0YuN0delLYvpqjhScVZ6ngfaCqEhSBYPmSuddpQ1feoOke84MluN8D0Zyu32eSavj7KIf233ul70AsO9Npvftj9w?width=1024&height=768&cropmode=none" class="darken"><div class="text"><center>Humans vol. 2<br></center></div><img src="https://hahw3q.db.files.1drv.com/y4mWZUDlsItWK6b8qjiI62D_mW2BeykwiWhZDGN4R5S922uIMyvXksp7A60K-ktAgYxk9fKjVKnvzv-8Gh8Z9GaetVOZuUrYuE4_NUe66M2xMVvaNoV8A27aI-bbQMxZj0YuN0delLYvpqjhScVZ6ngfaCqEhSBYPmSuddpQ1feoOke84MluN8D0Zyu32eSavj7KIf233ul70AsO9Npvftj9w?width=1024&height=768&cropmode=none" style="margin-top:20px"width="100%"></a><br>
  </div>
  </div> -->


<div class="row">
  <div class="col-md-8 col-md-offset-2 panel">

<p>
  By augmenting the environment, there are a few things that I aim at achieving: introducing a new, unfamiliar environment to the animal by introducting a set of new visuals and auditory cues, along with perhaps adjusted temperature and humidity to emulate the environment. While with such a setting it would certainly be possible to augment a reality centered around humans, as they have developed a range of devices set for the purpose of themselves, to the extent of even calibrating all the machinery to imitate the exact representation of audiovisual environments perceived by humans or even augmenting them, I would expect to have such an environment not work appropriately at least straightaway perhaps just due to the fact of how the senses vary between the species. Nevertheless, I wonder if wallabies would feel comfortable to spend time at an environment that would resemble tropical forests and now while tammar wallabies can't survive when it's over 40 degrees Centigrade (and rendering such environments with temperature and humidity would certainly be have no sense and be expensive), perhaps they may become comfortable if it's just the forest itself, with appropriate sounds elicited by other animals and the temperature just appropriate for them. Or even environments resembling the north pole, perhaps not due to the representation of the north pole itself but perhaps just the set of visual cues of white and blue could appeal to them, rendering a new appropriate environment for them to rest at and spend time.
</p>

<p>
  While I understand such an environment cannot be provided as a substitute to an actual, natural environment and the fidelity of the projection will never be of absolutely sufficient quality due to shadows generated by moving objects such as kangaroos themselves and just the resolution is not going to be ever appropriate. Nevertheless, it might be the case, that for kangaroos/wallabies/wallaroos who are not familiar with such new environments, may actually become interested. These particular species need to migrate (depending on the kangaroos, could go up to tens of kilometers of search for food) and so they need to be able to adapt to a variety of environments. I also think, many people like to travel. Some animals do travel for the purpose of their survival, think - many different birds, which will fly seasonally at times for thousands of kilometers. Perhaps kangaroos do not quite do that, certainly not wallabies but perhaps, despite there might not be one specific evolutionary benefit for them, they still may find some usecase of liking in such (environments) and hence, potentially lead to enriching their lives, in the end defining what enrichment is remains as a quite difficult task in term of refering that term to animals, especially wild and those placed in enclosures.
</p>


      </div><br>
</div>

</div>
<div class="con2">
<div class="row">
  <div class="col-md-8 col-md-offset-2 panel">

<p>
  There are some issues that I foresee nevertheless, especially in terms of Tammar Wallabies in particular. They are apparently nocturnal species, although many of their activities will take place during the same, some will take place during the night. Projecting dark environments is a particularly difficult task, as long as I know, that is hardly possible due to a projection mapping, well, being literally projection of light. There are probably some ways to alleviate that issue, perhaps it might be possible to just render some environments in grayscale and by that, giving an impression of an environment that is explored during the night. There is also the question whether wallabies would perceive the environment as one that really differs based on different projections mapped. Perhaps physical changes to the environment would be necessary by the introduction of specific leaves, grass, ground and other props to truly enhance the potentially enriching experience. Although, naturally such augmentations have been already portrayed in the mass media, at times in quite gloomy way such as in Black Mirror but they are also still being experimented on in forms of prototypes for enrichment of human lives. Still, seeing the potential problems with such solutions should not be overlooked.
</p>


      </div><br>
</div>

<center>
<iframe width="50%" src="https://www.youtube.com/embed/H8FwT1LCxew" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center><br>

<center>
  <iframe width="50%" src="https://www.youtube.com/embed/2MqGrF6JaOM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center><br>

<center>
<img width="50%" src="http://geekroniques.fr/wp-content/uploads/2014/08/vlcsnap-2014-08-26-14h37m46s8.png">
</center><br>

<div class="row">
  <div class="col-md-8 col-md-offset-2 panel">

<p>
  For the purpose of the prototype I created a few environments, that could give an idea of how the prototype could potentially work. In real world, it would not be that immersive that you would see so far outside, although potentially that could be simulated in a few ways by changing the actual 'dome' environment, perhaps involving a few projectors instead of a system of prisms and mirrors. Nevertheless, the combination of audiovisual cues kept at a fidelity enough to keep, potentially, a wallaby immersed within the space to perhaps interact with other wallabies and or rest, first of all generate interest and see how it reacts, whether it likes it or not. This could lead to an idea that what I am trying to achieve is to perhaps introduce a toy of sorts which I'd argue against, as what I'm trying to do is simulate an environment that would be otherwise just difficult to introduce, pretty much as humans do for augmenting their own reality and introducing a mixed reality systems of their own (I should have used this term probably from the very beginning, although with so many different realities existing even I found myself quite lost).
</p>

<p>
  I introduced three conceptual environments: arctic, subtropical and temperate.
</p>
</div>
</div>

<center><h1>Research</h1></center><br>

<div class="row">
  <div class="col-md-8 col-md-offset-2 panel">
<p>
  Some research was previously conducted around the theme of Kangaroos, Wallabies and other endemic species of Australia in conjunction with the idea of core theme of Enrichment itself.
</p>
</div>
</div>

<center>
<iframe src="4.html" width="80%" style="height:50vw"></iframe>
</center><br>

<div class="row">
<center>
<div class="col-lg-8 col-lg-offset-2">
<a data-flickr-embed="true" class="darken"  href="Blog/Safaris/5.html"><div class="text">That's next level</div><img src="https://jkbf2g.by.files.1drv.com/y4mC2yicjLdcIC81PvfCTwQpai7rQv18T3SVS5NnvbOhbVmr9KuhuyG1qYKdcdlKMJPXJ3H9b9g1xIt-8d3LfTYp2r4LLm68IY93qYhLT1Ud19WMZ6FytxubMfbHf6ySoREttlNBv3bb_6fp-N9Z6ckQHjIn-mntqTUQV8F8CBSCqhvIsqW6W3u59DcLJOu_1_dQG1Bohw1b6oqHFyD3RN5XQ?width=3240&height=1819&cropmode=none" width="75%"></a><br>
</div>
</center>
</div>

<div class="row">
  <div class="col-md-8 col-md-offset-2 panel">
<p>
  Following up on Harpreet's proposed source of postdoctoral research conducted at University of Melbourne by Sarah Webber, in line with the mixed reality idea suggested for Enrichment II for Design in Safaris, I read into the details of how mixed reality was introduced to Orangutans. This is almost exactly what I am proposing, although at a limited degree and for non-human species that are very closely related to humans themselves, which seems to entail a focus on interaction and having the technologies introduced at limited capacity as opposed to Enrichment II idea of turning an entire room into a rather static, yet still mixed reality environment. At this point, I have a hunch that introducing dynamic elements into the place will generate natural anxiety in animals, triggering a fight or flight response, which may be different for those kept in enclosures. Although at this point I assume all animals kepts at Zoos are in fact wild animals, non-domesticated.
</p>

<p>
  Related work could include Koko, which (it feels weird by saying it but I guess you could call it a lifelong) project in which a Gorilla was raised, technically by a human and taught as much as thought best in terms of how to communicate, primarily by the use of sign language. I believe in terms of cognitive capabilities these species are related, to humans as well and therefore more aware and as showcased during one of the lectures, they can exceed in certain tasks compared to humans, such as selecting a series of numbers in a sequence that are scattered across a monitor after showcasing which is which for a fraction of a second (as I believe it was?). It may be worth exploring how other animals react to mixed reality technologies, wallabies ought to be more open due to them being highly adaptable species but we'll see. I wonder whether the concept of uncanny valley exists in a form in case of animals or whether low-fidelity projected environments will be enough.
</p>

<p>
  Apparently Orangutans were very involved with the technology, however they could not interact with them the way they wanted as it limited them to using fingertips. Instead, Kinect was used to create dynamic projection mappings by the use of abstract forms, art created by Orangutans themselves. The aim was the enrichment of their lives, therefore very in line with what they do. Natural user interfaces were the focus, as the collaboration involved multiple parties: Microsoft, University of Melbourne and Victoria Zoo itself. Using the brain is apparently very important part of enrichment. Improving animal welfare and improving Conservational Behavioural Change, perception of not just betterment of humans but betterment of animals as well. Food and social interactions have potential to be explored in terms of the digital technologies.
</p>
</div>
</div>

<center>
<iframe width="50%" src="https://www.youtube.com/embed/SNuZ4OE6vCk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>

<br>
</div>
<div class="con3">
<center><h1>Prototyping</h1></center><br>

<div class="row">
  <div class="col-md-8 col-md-offset-2 panel">

<p>
  With no doubt, I am having some difficulties addressing assignments at sufficient quality on a weekly basis. I guess to draw a parallel, think of a functioning business. If it gets into trouble, it could go through a process called restructuring or just simply transformation, when it sees the bumpy road ahead. IBM apparently went through 7 major of those and look where they are. Exactly, you don't seem them anymore but they remain a very powerful firm nevertheless. Adjusting my way of working, thinking, the resources I need and the process of delivering assignments here at The New School are quite radically different, in terms that it is much more demanding at a much more significant manner, which is good. But it takes time to adjust and like usual, I get kind of none.
</p>

<p>
  In any case, over with the personal reflections and off to the prototyping part. I am not sure whether I addressed that sufficiently in the paragraphs before but one of the reasons I decided to go prototyping with unity is fairly simple, here I am drawing a parallel to a <a href="../../GradShow.html">graduation show I was designing as part of a team.</a> That having said, I went solo at a bit more specific venture: of recreating the idea of the team and rapidly prototyping in a virtual environment. Think about it, why should anyone first buy all resources to test out ideas, softcode/hardcode stuff, keep getting frustrated, bounce back and forth from failing prototypes and delivering something that ultimately you were not happy with, you would if you spent much more time on it but it seems I'll never be getting for a couple of next weeks now. So instead of spending $$$$ on materials, wasting time of the fabrication staff and going through a very complicated process of raising a prototype, involving multiple stakeholders in the process, I decided to go Fuad way and go through a very complicated process but one, that just has very few (and so less) potential failing points that can appear underway - as I would call it - extreme prototyping in Unity.
</p>
</div>
</div>

<div class="row">
<center>
<div class="col-lg-8 col-lg-offset-2">
<a data-flickr-embed="true" class="darken"  href="Blog/Safaris/5.html"><div class="text">Arctic Environment</div><img src="https://jkbi2g.by.files.1drv.com/y4maU55LeuqkSP2d0L6OpeeEj1vDeN1ecFoEB8Od7m855Bz-Nh22LzotN518upZ3bIJGixW-B_Ns2AoBzZ8BgxMMdHcLyuuz77oRpe76zMX_UCHap3X-MdhhpzHrGQLD_SoCiPym08TiXAeqRiRMB0cYAhF0RTyyuLgryf_M-DTFWwUjFJPBAcWhghRZQmYcDWVHWk4vJYMlB98aCqGrkE3kw?width=2124&height=1255&cropmode=none" width="75%"></a><br>
</div>
</center>
</div>

<div class="row">
  <div class="col-md-8 col-md-offset-2 panel">
<p>
  See, the thing is, my idea that concerns a whole area to be transformed, can be potentially tested in a virtual environment. Some elements can be taken quite much further and emulated in a neat fashion. I believe I already mentioned the obvious constraints that can appear but perhaps undertaking the project from the original standpoint: some miniaturized computer and a projector with a set of prisms and mirrors that would allow for a well dispersed colorful environment resembling other environments to be deployed at areas which cannot introduce too much of a variety for the animals it is home to. Emulating a variety of features is tricky and my knowledge of Unity is still developing but I believe in this particular case the use of Unity in particular is the optimal way of addressing this part of an assignment/homework. One, that potentially can extend onto other animals, once you think about it and get be flexed to quite great propotions and in addition, it may be possible to combine it with other systems such as Arduino, Processing, all stitched up in any way that may be relevant so that the enrichment actually occurs. One that is certainly very hard to define, ever since animals do not tend to speak in the very same language as humans but even if we take an aim for improving animals' physical wellbeing, this may be achieved with technologies. If not physical wellbeing itself, introducing what about psychological? Perhaps I'll go a bit anthropodenial here but don't at least certain animals share at least some humans' need for exploration? Sensing new cues, previously unknown? To learn about the surrounding environment? Like I said, there are some serious limitations in terms of how all this can be portrayed in a virtual environment but I think you get the idea so far and you may run those yourself if you're interested as I am attaching the prototype underneath.
</p>
</div>
</div>


</div>
<div class="con4">

<div class="row">
<center>
<div class="col-lg-8 col-lg-offset-2">
<a data-flickr-embed="true" class="darken"  href="Blog/Safaris/5.html"><div class="text">Subtropical Environment</div><img src="https://jkbh2g.by.files.1drv.com/y4mWahWDaTaTo42cX8Jt6U3dlGpT4OBP9WkTy63e7W3vjlCobtB6aeEbEV-kBjnGh_8StTeO87wuwt-EY8ZhwBJ4_lj25USg3Dqdo2x9n0eARcH1cgHFrWoq7fC1yd451MgWWiEtRNM1vsYgEE4gfL3U478WxnfjsfUywYWaaGDYbP6u05JOJVTq1WTrRPwjGpepAsRkcfUeesquTzlit0yNA?width=2127&height=1256&cropmode=none" width="75%"></a><br>
</div>
</center>
</div>

<div class="row">
  <div class="col-md-8 col-md-offset-2 panel">
<p>
  I have introduced a variety of assets that originate from Creative Coding: Unity course, Unity's Standard Assets with the addition of some scripts that I have reworked in conjunction with the engine's trigger system, resulting in the simulation of a variety of environments. Two sounds were ripped from Call of Duty: Modern Warfare 2 videogame, as I am familiar with the file system and have knowledge of what the game entails in terms of the sounds themselves, which I found to be relevant to the environment involved.
</p>

<p>
  I had some issues getting the WebGL version up and running. On one hand, I'm kinda running out of space on my GitHub repository, the limit is usually 1 GB, in my case I'm reaching 750MB and while there is a lot of assets that I should easily get rid of, this will take time, lots of it I just simply don't have. Then, there is a different color profile for WebGL, Gamma instead of Linear. Personally I prefer Linear due to enhanced contrast and just simply nicer rendering but it seems that only gamma is allowed for Web browsers (and so WebGL), which imposes some serious constraints and generated additional workload to calibrate the color system. The endgame is relatively rewarding, there is much that could have been introduced to make the experience much better (which I may improve later on) but the basic simulation of how the system would work is in place. After having looked into the interactive part of how projection mapping could be combined with Kinect however, now I am starting to think about incorporating interactive elements but that can come later.
</p>

<p>
  What I personally find particularly interesting is that based on the Unity prototype, I could potentially introduce interactive elements within the Unity system itself. Therefore, what I am in fact constructing here is an evolutionary prototype, which I can continuously improve without dedicating much of any resources. If I want to, I can create a virtual experience within a web browser, I can also port that into smartphones (on which it just may work to some degree once scripts are iterated), virtual reality headsets of all sorts - google cardboard, oculus go, htc vive and alike. All of which is exactly, what I aimed for by constructing this prototype in Unity, so that there is little liability, maximum performance and flexibility and to give the most appropriate idea of what I am in fact aiming for to achieve here. And I am happy to see that perhaps my attempt at enrichment may not quite be amiss in the end.
</p>
</div>
</div>

<div class="row">
<center>
<div class="col-lg-8 col-lg-offset-2">
<a data-flickr-embed="true" class="darken"  href="Blog/Safaris/5.html"><div class="text">'Strayan' Environment</div><img src="https://jkbg2g.by.files.1drv.com/y4mK-6EVngFwvsMltN966FNt_Nh7uRmdE3LE6q7wRJChS-N05IS9RttLW61E1IaUqUiNYkOzYA26KwsBkOZpePvNhhn45_9YhOolhkP97m5xA0jOM-Oq8uh8SuejRKXUl_NcQ9RfQFKAdwNIm1MzKNq5rOlc0YTPRjA1DRyIFnPQ8xgTg-Gq-eLW0gx7g_5MIp29DX0ebD1e4nDFW9M3Pi_Ww?width=2124&height=1257&cropmode=none" width="75%"></a><br>
</div>
</center>

<div class="row">
  <div class="col-md-8 col-md-offset-2 panel">
<p>Resources used for prototyping in Unity:<br><br>

- Unity Standard Assets<br>
- Assets supplied with for Creative Coding: Unity course at Parsons School of Design
- Call of Duty: Modern Warfare 2 nature sounds (ripped from game's directory)<br>
- Quite a bit of time<br><br>

Academic Resources:<br><br>

<a href="http://dx.doi.org/10.1145/3025453.3025729">1. Sarah Webber, Marcus Carter, Sally Sherwen, Wally Smith, Zaher Joukhadar, and Frank Vetere. 2017. Kinecting with Orangutans: Zoo Visitors' Empathetic Responses to Animals? Use of Interactive Technology. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI '17). ACM, New York, NY, USA, 6075-6088. DOI: https://doi.org/10.1145/3025453.3025729</a></p>
<p>
<a href="https://www.researchgate.net/publication/303293635_Interactive_Technology_and_Human-Animal_Encounters_at_the_Zoo">2. Webber, Sarah & Carter, Marcus & Smith, Wally & Vetere, Frank. (2016). Interactive Technology and Human-Animal Encounters at the Zoo. International Journal of Human-Computer Studies. 10.1016/j.ijhcs.2016.05.003. </a></p>
<p>
<a href="https://dl.acm.org/citation.cfm?id=2837011">3. Marcus Carter, Sarah Webber, and Sally Sherwen. 2015. Naturalism and ACI: augmenting zoo enclosures with digital technology. In Proceedings of the 12th International Conference on Advances in Computer Entertainment Technology (ACE '15). ACM, New York, NY, USA, Article 61, 5 pages. DOI: https://doi.org/10.1145/2832932.2837011
</a></p>
<p>
<a href="https://dl.acm.org/citation.cfm?id=2837014">4. Jean-Loup Rault, Sarah Webber, and Marcus Carter. 2015. Cross-disciplinary perspectives on animal welfare science and animal-computer interaction. In Proceedings of the 12th International Conference on Advances in Computer Entertainment Technology (ACE '15). ACM, New York, NY, USA, Article 56, 5 pages. DOI: https://doi.org/10.1145/2832932.2837014
</a></p>
<p>
  <a href="http://dx.doi.org/10.1145/2995257.3014066">5. Fiona French, Mark Kingston-Jones, David T. Schaller, Sarah Ellen Webber, Heli V채채t채j채, and Mark Campbell. 2016. Don't cut to the chase: hunting experiences for zoo animals and visitors. In Proceedings of the Third International Conference on Animal-Computer Interaction (ACI '16). ACM, New York, NY, USA, Article 19, 6 pages. DOI: https://doi.org/10.1145/2995257.3014066</a></p>

</p>
</div>
</div>

<center><h1>Prototype</h1></center><br>

<center>
    <div class="webgl-content">
      <div id="gameContainer" style="width: 80vw; height: 600px"></div>
      <div class="footer">
        <div class="webgl-logo" style="transform:translate(90%)"></div>
        <div class="fullscreen" onclick="gameInstance.SetFullscreen(1)" style="transform:translate(-480%)"></div>
      </div>
    </div>
  </center>

  <div class="row">
  <div class="col-md-8 col-md-offset-2 panel">
Use W to move forward and mouse to look around (there are some other interactions embedded too but these are the two most important ones)
  </div>
</div>


      </div><br>

<script src="footer.js"></script>

<script>
document.getElementById('button').onclick = function() {
    this.__toggle = !this.__toggle;
    var target = document.getElementById('hidden_content');
    if( this.__toggle) {
        target.style.height = target.scrollHeight+"px";
        this.firstChild.nodeValue = "Games and Play";
    }
    else {
        target.style.height = 0;
        this.firstChild.nodeValue = "Games and Play";
        setTimeout(function() {
       window.scrollTo(0,window.scrollY-300);
        TopscrollTo();
    }, 0);
    }
}
</script>

<script>
document.getElementById('button2').onclick = function() {
    this.__toggle = !this.__toggle;
    var target = document.getElementById('hidden_content2');
    if( this.__toggle) {
        target.style.height = target.scrollHeight+"px";
        this.firstChild.nodeValue = "Human-Computer Interaction 2";
    }
    else {
        target.style.height = 0;
        this.firstChild.nodeValue = "Human-Computer Interaction 2";
    }
}
</script>

    <script src="../../js/bootstrap.min.js"></script>
</body>
</html>